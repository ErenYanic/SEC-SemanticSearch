{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650ce215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting SEC EDGAR identity: Michael Mccallum, mike.mccalum@indigo.com\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 1 — Imports & Configuration\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from edgar import *\n",
    "from doc2dict import html2dict, unnest_dict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HUGGING_FACE_TOKEN\", \"\")\n",
    "\n",
    "# Set SEC EDGAR identity\n",
    "# SEC EDGAR requires an identity string (name + email).\n",
    "# Read from edgar-identity.txt (line 1: name, line 2: email) to avoid\n",
    "# committing credentials to version control.\n",
    "identity_name = os.getenv(\"EDGAR_IDENTITY_NAME\")\n",
    "identity_email = os.getenv(\"EDGAR_IDENTITY_EMAIL\")\n",
    "\n",
    "if identity_name and identity_email:\n",
    "    print(f\"Setting SEC EDGAR identity: {identity_name}, {identity_email}\")\n",
    "    set_identity(f\"{identity_name} {identity_email}\")\n",
    "else:\n",
    "    print(\"Warning: SEC EDGAR identity not set. Please provide name and email in environment variables.\")\n",
    "\n",
    "# ----- Constants -----\n",
    "EMBEDDING_MODEL_NAME = \"google/embeddinggemma-300m\"\n",
    "CHUNK_TOKEN_LIMIT = 500     # Hard upper bound (tokens ≈ whitespace-split words)\n",
    "CHUNK_TOLERANCE = 50        # Soft target: finalise a chunk once it reaches 450-550 tokens\n",
    "TOP_K = 5                   # Number of results to return\n",
    "\n",
    "# ----- Device -----\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kw7lqm47wj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filing: Filing(company='INTEL CORP', cik=50863, form='10-K', filing_date='2026-01-23', accession_no='0000050863-26-000011')\n",
      "Filed: 2026-01-23\n",
      "\n",
      "HTML length: 3,320,720 characters\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 2 — Fetch SEC Filing\n",
    "# =============================================================================\n",
    "\n",
    "TICKER = \"INTC\"\n",
    "FORM_TYPE = \"10-K\"\n",
    "\n",
    "company = Company(TICKER)\n",
    "filings = company.get_filings(form=FORM_TYPE)\n",
    "\n",
    "# Retrieve the most recent filing\n",
    "filing = filings[0]\n",
    "print(f\"Filing: {filing}\")\n",
    "print(f\"Filed: {filing.filing_date}\")\n",
    "\n",
    "# Download the HTML content\n",
    "html_content = filing.html()\n",
    "print(f\"\\nHTML length: {len(html_content):,} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "t6zmykmi5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 768 raw segments\n",
      "\n",
      "[table] UNITED STATES SECURITIES AND EXCHANGE COMMISSION > Washington, D.C. 20549\n",
      "  Washington, D.C. 20549...\n",
      "\n",
      "[table] FORM 10-K > (Mark One)\n",
      "  (Mark One) ☑ | ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934  | For the fiscal ye...\n",
      "\n",
      "[table] FORM 10-K > Commission File Number: 000-06217\n",
      "  Commission File Number: 000-06217...\n",
      "\n",
      "[table] INTEL CORPORATION\n",
      "  (Exact name of registrant as specified in its charter) Delaware (State or other jurisdiction of incorporation or organiz...\n",
      "\n",
      "[table] INTEL CORPORATION\n",
      "  Title of each class | Trading symbol | Name of each exchange on which registered Common stock, $0.001 par value | INTC |...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 3 — Parse HTML to Dictionary & Extract Segments\n",
    "# =============================================================================\n",
    "\n",
    "def extract_segments(dct, path=\"\", segments=None):\n",
    "    \"\"\"\n",
    "    Recursively traverse the doc2dict output and extract text segments\n",
    "    with their full hierarchical path (e.g. 'Part I > Item 1 > Business').\n",
    "\n",
    "    Each segment is a dict with keys: 'path', 'type', 'content'.\n",
    "    \"\"\"\n",
    "    if segments is None:\n",
    "        segments = []\n",
    "\n",
    "    if not isinstance(dct, dict):\n",
    "        return segments\n",
    "\n",
    "    # Build the current path from 'title' if present\n",
    "    current_path = path\n",
    "    if \"title\" in dct and isinstance(dct[\"title\"], str):\n",
    "        title = dct[\"title\"].strip()\n",
    "        if title:\n",
    "            current_path = f\"{path} > {title}\" if path else title\n",
    "\n",
    "    # Extract text content\n",
    "    for key in (\"text\", \"textsmall\"):\n",
    "        if key in dct and isinstance(dct[key], str):\n",
    "            text = dct[key].strip()\n",
    "            if text:\n",
    "                segments.append({\n",
    "                    \"path\": current_path or \"(root)\",\n",
    "                    \"type\": key,\n",
    "                    \"content\": text,\n",
    "                })\n",
    "\n",
    "    # Extract table content — convert to a readable string representation\n",
    "    if \"table\" in dct:\n",
    "        table = dct[\"table\"]\n",
    "        table_parts = []\n",
    "\n",
    "        if isinstance(table, dict):\n",
    "            if table.get(\"title\"):\n",
    "                table_parts.append(str(table[\"title\"]))\n",
    "            if table.get(\"preamble\"):\n",
    "                table_parts.append(str(table[\"preamble\"]))\n",
    "            if table.get(\"data\"):\n",
    "                for row in table[\"data\"]:\n",
    "                    table_parts.append(\" | \".join(str(cell) for cell in row))\n",
    "            if table.get(\"footnotes\"):\n",
    "                for fn in table[\"footnotes\"]:\n",
    "                    table_parts.append(str(fn))\n",
    "            if table.get(\"postamble\"):\n",
    "                table_parts.append(str(table[\"postamble\"]))\n",
    "        elif isinstance(table, list):\n",
    "            for row in table:\n",
    "                table_parts.append(\" | \".join(str(cell) for cell in row))\n",
    "\n",
    "        table_text = \"\\n\".join(table_parts).strip()\n",
    "        if table_text:\n",
    "            segments.append({\n",
    "                \"path\": current_path or \"(root)\",\n",
    "                \"type\": \"table\",\n",
    "                \"content\": table_text,\n",
    "            })\n",
    "\n",
    "    # Recurse into nested contents\n",
    "    contents = dct.get(\"contents\", {})\n",
    "    if isinstance(contents, dict):\n",
    "        for key in contents:\n",
    "            extract_segments(contents[key], current_path, segments)\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "# Parse the filing HTML\n",
    "parsed = html2dict(html_content)\n",
    "\n",
    "# Handle the 'document' wrapper if present\n",
    "root = parsed.get(\"document\", parsed)\n",
    "all_segments = []\n",
    "if isinstance(root, dict):\n",
    "    for key in root:\n",
    "        extract_segments(root[key], segments=all_segments)\n",
    "\n",
    "print(f\"Extracted {len(all_segments):,} raw segments\")\n",
    "\n",
    "# Show a sample\n",
    "for seg in all_segments[:5]:\n",
    "    preview = seg[\"content\"][:120].replace(\"\\n\", \" \")\n",
    "    print(f\"\\n[{seg['type']}] {seg['path']}\")\n",
    "    print(f\"  {preview}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbzpwdv8fh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks after splitting: 357\n",
      "Token range: 1 – 550\n",
      "Mean tokens per chunk: 86\n",
      "Chunks exceeding 500 tokens: 5\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 4 — Chunk Long Segments (sentence-boundary aware)\n",
    "# =============================================================================\n",
    "\n",
    "def token_count(text):\n",
    "    \"\"\"Approximate token count using whitespace splitting.\"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "def chunk_segment(segment, limit=CHUNK_TOKEN_LIMIT, tolerance=CHUNK_TOLERANCE):\n",
    "    \"\"\"\n",
    "    Split a segment into chunks that respect the token limit.\n",
    "\n",
    "    Sentences are never cut in half. A chunk is finalised when the next\n",
    "    sentence would push it past the limit, even if the chunk ends at\n",
    "    e.g. 476 tokens (within the ±tolerance band).\n",
    "\n",
    "    Returns a list of segment dicts, each inheriting the original path.\n",
    "    \"\"\"\n",
    "    content = segment[\"content\"]\n",
    "    total_tokens = token_count(content)\n",
    "\n",
    "    # If the segment already fits, return it as-is\n",
    "    if total_tokens <= limit:\n",
    "        return [segment]\n",
    "\n",
    "    # Split on sentence boundaries (full stop, exclamation mark, question mark)\n",
    "    sentences = re.split(r\"(?<=[.!?])\\s+\", content)\n",
    "\n",
    "    chunks = []\n",
    "    current_sentences = []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = token_count(sentence)\n",
    "\n",
    "        # If a single sentence exceeds the limit, keep it whole rather than\n",
    "        # cutting mid-sentence — the tolerance band permits this.\n",
    "        if current_tokens + sentence_tokens > limit + tolerance and current_sentences:\n",
    "            chunks.append({\n",
    "                \"path\": segment[\"path\"],\n",
    "                \"type\": segment[\"type\"],\n",
    "                \"content\": \" \".join(current_sentences),\n",
    "            })\n",
    "            current_sentences = []\n",
    "            current_tokens = 0\n",
    "\n",
    "        current_sentences.append(sentence)\n",
    "        current_tokens += sentence_tokens\n",
    "\n",
    "    # Flush the remaining sentences\n",
    "    if current_sentences:\n",
    "        chunks.append({\n",
    "            \"path\": segment[\"path\"],\n",
    "            \"type\": segment[\"type\"],\n",
    "            \"content\": \" \".join(current_sentences),\n",
    "        })\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Apply chunking to all segments\n",
    "chunks = []\n",
    "for seg in all_segments:\n",
    "    chunks.extend(chunk_segment(seg))\n",
    "\n",
    "print(f\"Total chunks after splitting: {len(chunks):,}\")\n",
    "\n",
    "# Show token distribution\n",
    "token_counts = [token_count(c[\"content\"]) for c in chunks]\n",
    "print(f\"Token range: {min(token_counts)} – {max(token_counts)}\")\n",
    "print(f\"Mean tokens per chunk: {sum(token_counts) / len(token_counts):.0f}\")\n",
    "\n",
    "# Show how many exceed the limit (should only be single long sentences)\n",
    "over_limit = sum(1 for t in token_counts if t > CHUNK_TOKEN_LIMIT)\n",
    "print(f\"Chunks exceeding {CHUNK_TOKEN_LIMIT} tokens: {over_limit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "j8wspc4hntl",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffef099deb0540acb4525fda0fc4c2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/314 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'google/embeddinggemma-300m' on cuda\n",
      "Embedding 357 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0cd2e52f5a49389ebf6891c55693b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (357, 768)\n",
      "\n",
      "Stored 357 chunks in collection 'aapl_10_k'\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 5 — Embed & Store in ChromaDB\n",
    "# =============================================================================\n",
    "\n",
    "# Load the embedding model on GPU\n",
    "model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=DEVICE)\n",
    "print(f\"Loaded '{EMBEDDING_MODEL_NAME}' on {DEVICE}\")\n",
    "\n",
    "# Prepare texts and metadata\n",
    "texts = [c[\"content\"] for c in chunks]\n",
    "metadatas = [\n",
    "    {\n",
    "        \"path\": c[\"path\"],\n",
    "        \"type\": c[\"type\"],\n",
    "        \"ticker\": TICKER,\n",
    "        \"form_type\": FORM_TYPE,\n",
    "    }\n",
    "    for c in chunks\n",
    "]\n",
    "ids = [f\"{TICKER}_{FORM_TYPE}_{i}\" for i in range(len(chunks))]\n",
    "\n",
    "# Generate embeddings (batch encoding on GPU)\n",
    "print(f\"Embedding {len(texts):,} chunks...\")\n",
    "embeddings = model.encode(texts, batch_size=8, show_progress_bar=True, convert_to_numpy=True)\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "\n",
    "# Initialise ChromaDB (persistent local storage)\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection_name = f\"{TICKER}_{FORM_TYPE}\".lower().replace(\"-\", \"_\")\n",
    "\n",
    "# Delete existing collection if present (for clean re-runs)\n",
    "try:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "collection = chroma_client.create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"hnsw:space\": \"cosine\"},\n",
    ")\n",
    "\n",
    "# Upsert into ChromaDB\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    embeddings=embeddings.tolist(),\n",
    "    documents=texts,\n",
    "    metadatas=metadatas,\n",
    ")\n",
    "print(f\"\\nStored {collection.count():,} chunks in collection '{collection_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fuo82bjm7fm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 6 — Semantic Search Function\n",
    "# =============================================================================\n",
    "\n",
    "def semantic_search(query, top_k=TOP_K):\n",
    "    \"\"\"Embed the query and return the top-k most relevant chunks.\"\"\"\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True).tolist()\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embedding,\n",
    "        n_results=top_k,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"],\n",
    "    )\n",
    "\n",
    "    print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "    print(f\"{'Rank':<5} {'Score':<8} {'Section Path'}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for i in range(len(results[\"ids\"][0])):\n",
    "        # ChromaDB returns cosine distance; similarity = 1 - distance\n",
    "        distance = results[\"distances\"][0][i]\n",
    "        similarity = 1 - distance\n",
    "        path = results[\"metadatas\"][0][i][\"path\"]\n",
    "        doc = results[\"documents\"][0][i]\n",
    "        seg_type = results[\"metadatas\"][0][i][\"type\"]\n",
    "\n",
    "        print(f\"\\n#{i + 1:<4} {similarity:.4f}  [{seg_type}] {path}\")\n",
    "        print(f\"     {doc[:200]}...\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "umovo9i4km",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \"What are the main risk factors?\"\n",
      "\n",
      "Rank  Score    Section Path\n",
      "================================================================================\n",
      "\n",
      "#1    0.4158  [text] TABLE OF CONTENTS > Internal-Use Software > Item 7A.    Quantitative and Qualitative Disclosures About Market Risk\n",
      "     The Company is exposed to economic risk from interest rates and foreign exchange rates. The Company uses various strategies to manage these risks; however, they may still impact the Company’s consolid...\n",
      "\n",
      "#2    0.4064  [table] introduction\n",
      "     introduction...\n",
      "\n",
      "#3    0.3901  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1C.    Cybersecurity\n",
      "     For a discussion of the Company’s cybersecurity-related risks, see Item 1A of this Form 10-K under the heading “Risk Factors.”...\n",
      "\n",
      "#4    0.3832  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors\n",
      "     The following summarizes factors that could have a material adverse effect on the Company’s business, reputation, results of operations, financial condition and stock price. The Company may not be abl...\n",
      "\n",
      "#5    0.3765  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Business Risks > The Company depends on component and product manufacturing and logistical services provided by outsourcing partners, many of which are located outside of the U.S.\n",
      "     Changes or additions to the Company’s supply chain require considerable time and resources and involve significant risks and uncertainties, including exposure to additional regulatory and operational ...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Query: \"Revenue and net income figures\"\n",
      "\n",
      "Rank  Score    Section Path\n",
      "================================================================================\n",
      "\n",
      "#1    0.5394  [text] CONSOLIDATED STATEMENTS OF CASH FLOWS > Apple Inc. > Note 1 – Summary of Significant Accounting Policies > Revenue\n",
      "     The Company records revenue net of taxes collected from customers that are remitted to governmental authorities....\n",
      "\n",
      "#2    0.4806  [table] CONSOLIDATED STATEMENTS OF CASH FLOWS > Apple Inc. > Vendor Non-Trade Receivables > Note 13 – Segment Information and Geographic Data\n",
      "     | 2024\n",
      "Americas | 2024\n",
      "Europe | 2024\n",
      "Greater\n",
      "China | 2024\n",
      "Japan | 2024\n",
      "Rest of\n",
      "Asia Pacific | 2024\n",
      "Corporate | 2024\n",
      "Total\n",
      "Net sales | $167,045 | $101,328 | $66,952 | $25,052 | $30,658 | $— | $391,035\n",
      "...\n",
      "\n",
      "#3    0.4588  [table] CONSOLIDATED STATEMENTS OF COMPREHENSIVE INCOME > (In millions)\n",
      "     (In millions)\n",
      " | Years ended\n",
      "September 27,\n",
      "2025 | Years ended\n",
      "September 28,\n",
      "2024 | Years ended\n",
      "September 30,\n",
      "2023\n",
      "Net income | $112,010 | $93,736 | $96,995\n",
      "Other comprehensive income/(loss): |  |  | \n",
      "...\n",
      "\n",
      "#4    0.4525  [table] CONSOLIDATED STATEMENTS OF CASH FLOWS > (In millions)\n",
      "     (In millions)\n",
      " | Years ended\n",
      "September 27,\n",
      "2025 | Years ended\n",
      "September 28,\n",
      "2024 | Years ended\n",
      "September 30,\n",
      "2023\n",
      "Cash, cash equivalents, and restricted cash and cash equivalents, beginning balances |...\n",
      "\n",
      "#5    0.4396  [table] CONSOLIDATED STATEMENTS OF OPERATIONS > (In millions, except number of shares, which are reflected in thousands, and per-share amounts)\n",
      "     (In millions, except number of shares, which are reflected in thousands, and per-share amounts)\n",
      " | Years ended\n",
      "September 27,\n",
      "2025 | Years ended\n",
      "September 28,\n",
      "2024 | Years ended\n",
      "September 30,\n",
      "2023\n",
      "Net ...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Query: \"Supply chain and manufacturing operations\"\n",
      "\n",
      "Rank  Score    Section Path\n",
      "================================================================================\n",
      "\n",
      "#1    0.5343  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Business Risks > The Company depends on component and product manufacturing and logistical services provided by outsourcing partners, many of which are located outside of the U.S.\n",
      "     Changes or additions to the Company’s supply chain require considerable time and resources and involve significant risks and uncertainties, including exposure to additional regulatory and operational ...\n",
      "\n",
      "#2    0.4894  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Macroeconomic and Industry Risks > The Company’s business can be impacted by political events, trade and other international disputes, geopolitical tensions, conflict, terrorism, natural disasters, public health issues, industrial accidents and other business interruptions.\n",
      "     Such events can make it difficult or impossible for the Company to manufacture and deliver products to its customers, create delays and inefficiencies in the Company’s supply and manufacturing chain, ...\n",
      "\n",
      "#3    0.4739  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Business Risks > Future operating results depend upon the Company’s ability to obtain components in sufficient quantities on commercially reasonable terms.\n",
      "     Additionally, the Company’s new products often utilize custom components available from only one source. When a component or product uses new technologies, initial capacity constraints may exist until...\n",
      "\n",
      "#4    0.4686  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Macroeconomic and Industry Risks > The Company’s operations and performance depend significantly on global and regional economic conditions and adverse economic conditions can materially adversely affect the Company’s business, results of operations, financial condition and stock price.\n",
      "     The Company has international operations with sales outside the U.S. representing a majority of the Company’s total net sales. In addition, the Company’s global supply chain is large and complex and a...\n",
      "\n",
      "#5    0.4653  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Macroeconomic and Industry Risks > The Company’s business can be impacted by political events, trade and other international disputes, geopolitical tensions, conflict, terrorism, natural disasters, public health issues, industrial accidents and other business interruptions.\n",
      "     The Company’s operations are also subject to the risks of industrial accidents at its suppliers and contract manufacturers. While the Company’s suppliers are required to maintain safe working environm...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 7 — Demo Queries\n",
    "# =============================================================================\n",
    "\n",
    "# Example queries — adjust to match the filing content\n",
    "_ = semantic_search(\"What are the main risk factors?\")\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "_ = semantic_search(\"Revenue and net income figures\")\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "_ = semantic_search(\"Supply chain and manufacturing operations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_SEC_SemanticSearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

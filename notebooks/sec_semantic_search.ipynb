{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650ce215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting SEC EDGAR identity: Michael Mccallum, mike.mccalum@indigo.com\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 1 — Imports & Configuration\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from edgar import Company, set_identity\n",
    "from doc2dict import html2dict, unnest_dict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HUGGING_FACE_TOKEN\", \"\")\n",
    "\n",
    "# Set SEC EDGAR identity\n",
    "# SEC EDGAR requires an identity string (name + email).\n",
    "# Read from edgar-identity.txt (line 1: name, line 2: email) to avoid\n",
    "# committing credentials to version control.\n",
    "identity_name = os.getenv(\"EDGAR_IDENTITY_NAME\")\n",
    "identity_email = os.getenv(\"EDGAR_IDENTITY_EMAIL\")\n",
    "\n",
    "if identity_name and identity_email:\n",
    "    print(f\"Setting SEC EDGAR identity: {identity_name}, {identity_email}\")\n",
    "    set_identity(f\"{identity_name} {identity_email}\")\n",
    "else:\n",
    "    print(\"Warning: SEC EDGAR identity not set. Please provide name and email in environment variables.\")\n",
    "\n",
    "# ----- Constants -----\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "CHUNK_TOKEN_LIMIT = 500     # Hard upper bound (tokens ≈ whitespace-split words)\n",
    "CHUNK_TOLERANCE = 50        # Soft target: finalise a chunk once it reaches 450+ tokens\n",
    "TOP_K = 5                   # Number of results to return\n",
    "\n",
    "# ----- Device -----\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "kw7lqm47wj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filing: Filing(company='Apple Inc.', cik=320193, form='10-K', filing_date='2025-10-31', accession_no='0000320193-25-000079')\n",
      "Filed: 2025-10-31\n",
      "\n",
      "HTML length: 1,520,208 characters\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 2 — Fetch SEC Filing\n",
    "# =============================================================================\n",
    "\n",
    "TICKER = \"AAPL\"\n",
    "FORM_TYPE = \"10-K\"\n",
    "\n",
    "company = Company(TICKER)\n",
    "filings = company.get_filings(form=FORM_TYPE)\n",
    "\n",
    "# Retrieve the most recent filing\n",
    "filing = filings[0]\n",
    "print(f\"Filing: {filing}\")\n",
    "print(f\"Filed: {filing.filing_date}\")\n",
    "\n",
    "# Download the HTML content\n",
    "html_content = filing.html()\n",
    "print(f\"\\nHTML length: {len(html_content):,} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "t6zmykmi5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 354 raw segments\n",
      "\n",
      "[table] introduction\n",
      "  introduction...\n",
      "\n",
      "[table] SECURITIES AND EXCHANGE COMMISSION > Washington, D.C. 20549\n",
      "  Washington, D.C. 20549...\n",
      "\n",
      "[table] FORM 10-K\n",
      "  FORM 10-K (Mark One)...\n",
      "\n",
      "[table] FORM 10-K > 001-36743\n",
      "  001-36743...\n",
      "\n",
      "[table] FORM 10-K > Apple Inc. > (Exact name of Registrant as specified in its charter)\n",
      "  California | 94-2404110 (State or other jurisdiction of incorporation or organization) | (I.R.S. Employer Identification...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 3 — Parse HTML to Dictionary & Extract Segments\n",
    "# =============================================================================\n",
    "\n",
    "def extract_segments(dct, path=\"\", segments=None):\n",
    "    \"\"\"\n",
    "    Recursively traverse the doc2dict output and extract text segments\n",
    "    with their full hierarchical path (e.g. 'Part I > Item 1 > Business').\n",
    "\n",
    "    Each segment is a dict with keys: 'path', 'type', 'content'.\n",
    "    \"\"\"\n",
    "    if segments is None:\n",
    "        segments = []\n",
    "\n",
    "    if not isinstance(dct, dict):\n",
    "        return segments\n",
    "\n",
    "    # Build the current path from 'title' if present\n",
    "    current_path = path\n",
    "    if \"title\" in dct and isinstance(dct[\"title\"], str):\n",
    "        title = dct[\"title\"].strip()\n",
    "        if title:\n",
    "            current_path = f\"{path} > {title}\" if path else title\n",
    "\n",
    "    # Extract text content\n",
    "    for key in (\"text\", \"textsmall\"):\n",
    "        if key in dct and isinstance(dct[key], str):\n",
    "            text = dct[key].strip()\n",
    "            if text:\n",
    "                segments.append({\n",
    "                    \"path\": current_path or \"(root)\",\n",
    "                    \"type\": key,\n",
    "                    \"content\": text,\n",
    "                })\n",
    "\n",
    "    # Extract table content — convert to a readable string representation\n",
    "    if \"table\" in dct:\n",
    "        table = dct[\"table\"]\n",
    "        table_parts = []\n",
    "\n",
    "        if isinstance(table, dict):\n",
    "            if table.get(\"title\"):\n",
    "                table_parts.append(str(table[\"title\"]))\n",
    "            if table.get(\"preamble\"):\n",
    "                table_parts.append(str(table[\"preamble\"]))\n",
    "            if table.get(\"data\"):\n",
    "                for row in table[\"data\"]:\n",
    "                    table_parts.append(\" | \".join(str(cell) for cell in row))\n",
    "            if table.get(\"footnotes\"):\n",
    "                for fn in table[\"footnotes\"]:\n",
    "                    table_parts.append(str(fn))\n",
    "            if table.get(\"postamble\"):\n",
    "                table_parts.append(str(table[\"postamble\"]))\n",
    "        elif isinstance(table, list):\n",
    "            for row in table:\n",
    "                table_parts.append(\" | \".join(str(cell) for cell in row))\n",
    "\n",
    "        table_text = \"\\n\".join(table_parts).strip()\n",
    "        if table_text:\n",
    "            segments.append({\n",
    "                \"path\": current_path or \"(root)\",\n",
    "                \"type\": \"table\",\n",
    "                \"content\": table_text,\n",
    "            })\n",
    "\n",
    "    # Recurse into nested contents\n",
    "    contents = dct.get(\"contents\", {})\n",
    "    if isinstance(contents, dict):\n",
    "        for key in contents:\n",
    "            extract_segments(contents[key], current_path, segments)\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "# Parse the filing HTML\n",
    "parsed = html2dict(html_content)\n",
    "\n",
    "# Handle the 'document' wrapper if present\n",
    "root = parsed.get(\"document\", parsed)\n",
    "all_segments = []\n",
    "if isinstance(root, dict):\n",
    "    for key in root:\n",
    "        extract_segments(root[key], segments=all_segments)\n",
    "\n",
    "print(f\"Extracted {len(all_segments):,} raw segments\")\n",
    "\n",
    "# Show a sample\n",
    "for seg in all_segments[:5]:\n",
    "    preview = seg[\"content\"][:120].replace(\"\\n\", \" \")\n",
    "    print(f\"\\n[{seg['type']}] {seg['path']}\")\n",
    "    print(f\"  {preview}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbzpwdv8fh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks after splitting: 357\n",
      "Token range: 1 – 550\n",
      "Mean tokens per chunk: 86\n",
      "Chunks exceeding 500 tokens: 5\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 4 — Chunk Long Segments (sentence-boundary aware)\n",
    "# =============================================================================\n",
    "\n",
    "def token_count(text):\n",
    "    \"\"\"Approximate token count using whitespace splitting.\"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "def chunk_segment(segment, limit=CHUNK_TOKEN_LIMIT, tolerance=CHUNK_TOLERANCE):\n",
    "    \"\"\"\n",
    "    Split a segment into chunks that respect the token limit.\n",
    "\n",
    "    Sentences are never cut in half. A chunk is finalised when the next\n",
    "    sentence would push it past the limit, even if the chunk ends at\n",
    "    e.g. 476 tokens (within the ±tolerance band).\n",
    "\n",
    "    Returns a list of segment dicts, each inheriting the original path.\n",
    "    \"\"\"\n",
    "    content = segment[\"content\"]\n",
    "    total_tokens = token_count(content)\n",
    "\n",
    "    # If the segment already fits, return it as-is\n",
    "    if total_tokens <= limit:\n",
    "        return [segment]\n",
    "\n",
    "    # Split on sentence boundaries (full stop, exclamation mark, question mark)\n",
    "    sentences = re.split(r\"(?<=[.!?])\\s+\", content)\n",
    "\n",
    "    chunks = []\n",
    "    current_sentences = []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = token_count(sentence)\n",
    "\n",
    "        # If a single sentence exceeds the limit, keep it whole rather than\n",
    "        # cutting mid-sentence — the tolerance band permits this.\n",
    "        if current_tokens + sentence_tokens > limit + tolerance and current_sentences:\n",
    "            chunks.append({\n",
    "                \"path\": segment[\"path\"],\n",
    "                \"type\": segment[\"type\"],\n",
    "                \"content\": \" \".join(current_sentences),\n",
    "            })\n",
    "            current_sentences = []\n",
    "            current_tokens = 0\n",
    "\n",
    "        current_sentences.append(sentence)\n",
    "        current_tokens += sentence_tokens\n",
    "\n",
    "    # Flush the remaining sentences\n",
    "    if current_sentences:\n",
    "        chunks.append({\n",
    "            \"path\": segment[\"path\"],\n",
    "            \"type\": segment[\"type\"],\n",
    "            \"content\": \" \".join(current_sentences),\n",
    "        })\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Apply chunking to all segments\n",
    "chunks = []\n",
    "for seg in all_segments:\n",
    "    chunks.extend(chunk_segment(seg))\n",
    "\n",
    "print(f\"Total chunks after splitting: {len(chunks):,}\")\n",
    "\n",
    "# Show token distribution\n",
    "token_counts = [token_count(c[\"content\"]) for c in chunks]\n",
    "print(f\"Token range: {min(token_counts)} – {max(token_counts)}\")\n",
    "print(f\"Mean tokens per chunk: {sum(token_counts) / len(token_counts):.0f}\")\n",
    "\n",
    "# Show how many exceed the limit (should only be single long sentences)\n",
    "over_limit = sum(1 for t in token_counts if t > CHUNK_TOKEN_LIMIT)\n",
    "print(f\"Chunks exceeding {CHUNK_TOKEN_LIMIT} tokens: {over_limit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "j8wspc4hntl",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a17987d049b4382aba87c5f1da07a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'all-MiniLM-L6-v2' on cuda\n",
      "Embedding 357 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bf631bed5644fdbe015b8b8a331dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (357, 384)\n",
      "\n",
      "Stored 357 chunks in collection 'aapl_10_k'\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 5 — Embed & Store in ChromaDB\n",
    "# =============================================================================\n",
    "\n",
    "# Load the embedding model on GPU\n",
    "model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=DEVICE)\n",
    "print(f\"Loaded '{EMBEDDING_MODEL_NAME}' on {DEVICE}\")\n",
    "\n",
    "# Prepare texts and metadata\n",
    "texts = [c[\"content\"] for c in chunks]\n",
    "metadatas = [\n",
    "    {\n",
    "        \"path\": c[\"path\"],\n",
    "        \"type\": c[\"type\"],\n",
    "        \"ticker\": TICKER,\n",
    "        \"form_type\": FORM_TYPE,\n",
    "    }\n",
    "    for c in chunks\n",
    "]\n",
    "ids = [f\"{TICKER}_{FORM_TYPE}_{i}\" for i in range(len(chunks))]\n",
    "\n",
    "# Generate embeddings (batch encoding on GPU)\n",
    "print(f\"Embedding {len(texts):,} chunks...\")\n",
    "embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "\n",
    "# Initialise ChromaDB (persistent local storage)\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection_name = f\"{TICKER}_{FORM_TYPE}\".lower().replace(\"-\", \"_\")\n",
    "\n",
    "# Delete existing collection if present (for clean re-runs)\n",
    "try:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "collection = chroma_client.create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"hnsw:space\": \"cosine\"},\n",
    ")\n",
    "\n",
    "# Upsert into ChromaDB\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    embeddings=embeddings.tolist(),\n",
    "    documents=texts,\n",
    "    metadatas=metadatas,\n",
    ")\n",
    "print(f\"\\nStored {collection.count():,} chunks in collection '{collection_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fuo82bjm7fm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 6 — Semantic Search Function\n",
    "# =============================================================================\n",
    "\n",
    "def semantic_search(query, top_k=TOP_K):\n",
    "    \"\"\"Embed the query and return the top-k most relevant chunks.\"\"\"\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True).tolist()\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embedding,\n",
    "        n_results=top_k,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"],\n",
    "    )\n",
    "\n",
    "    print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "    print(f\"{'Rank':<5} {'Score':<8} {'Section Path'}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for i in range(len(results[\"ids\"][0])):\n",
    "        # ChromaDB returns cosine distance; similarity = 1 - distance\n",
    "        distance = results[\"distances\"][0][i]\n",
    "        similarity = 1 - distance\n",
    "        path = results[\"metadatas\"][0][i][\"path\"]\n",
    "        doc = results[\"documents\"][0][i]\n",
    "        seg_type = results[\"metadatas\"][0][i][\"type\"]\n",
    "\n",
    "        print(f\"\\n#{i + 1:<4} {similarity:.4f}  [{seg_type}] {path}\")\n",
    "        print(f\"     {doc[:200]}...\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "umovo9i4km",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \"What are the main risk factors?\"\n",
      "\n",
      "Rank  Score    Section Path\n",
      "================================================================================\n",
      "\n",
      "#1    0.5558  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1C.    Cybersecurity\n",
      "     For a discussion of the Company’s cybersecurity-related risks, see Item 1A of this Form 10-K under the heading “Risk Factors.”...\n",
      "\n",
      "#2    0.5306  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors\n",
      "     The following summarizes factors that could have a material adverse effect on the Company’s business, reputation, results of operations, financial condition and stock price. The Company may not be abl...\n",
      "\n",
      "#3    0.4827  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Macroeconomic and Industry Risks > The Company’s business can be impacted by political events, trade and other international disputes, geopolitical tensions, conflict, terrorism, natural disasters, public health issues, industrial accidents and other business interruptions.\n",
      "     The Company’s operations are also subject to the risks of industrial accidents at its suppliers and contract manufacturers. While the Company’s suppliers are required to maintain safe working environm...\n",
      "\n",
      "#4    0.4728  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Legal and Regulatory Compliance Risks > The Company is subject to complex and changing laws and regulations worldwide, which exposes the Company to potential liabilities, increased costs and other adverse effects on the Company’s business.\n",
      "     Risks and costs related to new and changing laws, regulations, executive orders, directives, and enforcement priorities increase as the Company’s products and services are introduced into specialized ...\n",
      "\n",
      "#5    0.4689  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Business Risks > The Company depends on component and product manufacturing and logistical services provided by outsourcing partners, many of which are located outside of the U.S.\n",
      "     Changes or additions to the Company’s supply chain require considerable time and resources and involve significant risks and uncertainties, including exposure to additional regulatory and operational ...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Query: \"Revenue and net income figures\"\n",
      "\n",
      "Rank  Score    Section Path\n",
      "================================================================================\n",
      "\n",
      "#1    0.5870  [table] TABLE OF CONTENTS > Wearables, Home and Accessories > Operating Expenses\n",
      "     Operating Expenses\n",
      "Operating expenses for 2025, 2024 and 2023 were as follows (dollars in millions):\n",
      "\n",
      "Research and development | 2025\n",
      " | 2025\n",
      "$34,550 | Change\n",
      "10 | Change\n",
      "10% | 2024\n",
      " | 2024\n",
      "$31,370 | ...\n",
      "\n",
      "#2    0.5431  [text] CONSOLIDATED STATEMENTS OF CASH FLOWS > Apple Inc. > Note 1 – Summary of Significant Accounting Policies > Revenue\n",
      "     The Company records revenue net of taxes collected from customers that are remitted to governmental authorities....\n",
      "\n",
      "#3    0.5428  [table] TABLE OF CONTENTS > The following discussion should be read in conjunction with the consolidated financial statements and accompanying notes included in Part II, Item 8 of this Form 10-K. This Item generally discusses 2025 and 2024 items and year-to-year comparisons between 2025 and 2024. Discussions of 2023 items and year-to-year comparisons between 2024 and 2023 are not included, and can be found in “Management’s Discussion and Analysis of Financial Condition and Results of Operations” in Part II, Item 7 of the Company’s Annual Report on Form 10-K for the fiscal year ended September 28, 2024. > Product, Service and Software Announcements > Segment Operating Performance\n",
      "     Segment Operating Performance\n",
      "The following table shows net sales by reportable segment for 2025, 2024 and 2023 (dollars in millions):\n",
      "\n",
      "Americas | 2025\n",
      "$178,353 | Change\n",
      "7 | Change\n",
      "7% | 2024\n",
      "$167,045 ...\n",
      "\n",
      "#4    0.5180  [table] CONSOLIDATED STATEMENTS OF CASH FLOWS > Apple Inc. > Note 2 – Revenue\n",
      "     | 2025 Form 10-K | 35 The following table shows disaggregated net sales, as well as the portion of total net sales that was previously deferred, for 2025, 2024 and 2023 (in millions):\n",
      " | 2025 | 2024 |...\n",
      "\n",
      "#5    0.5112  [table] CONSOLIDATED STATEMENTS OF OPERATIONS > (In millions, except number of shares, which are reflected in thousands, and per-share amounts)\n",
      "     (In millions, except number of shares, which are reflected in thousands, and per-share amounts)\n",
      " | Years ended\n",
      "September 27,\n",
      "2025 | Years ended\n",
      "September 28,\n",
      "2024 | Years ended\n",
      "September 30,\n",
      "2023\n",
      "Net ...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Query: \"Supply chain and manufacturing operations\"\n",
      "\n",
      "Rank  Score    Section Path\n",
      "================================================================================\n",
      "\n",
      "#1    0.6312  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Macroeconomic and Industry Risks > The Company’s operations and performance depend significantly on global and regional economic conditions and adverse economic conditions can materially adversely affect the Company’s business, results of operations, financial condition and stock price.\n",
      "     The Company has international operations with sales outside the U.S. representing a majority of the Company’s total net sales. In addition, the Company’s global supply chain is large and complex and a...\n",
      "\n",
      "#2    0.5585  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Macroeconomic and Industry Risks > The Company’s business can be impacted by political events, trade and other international disputes, geopolitical tensions, conflict, terrorism, natural disasters, public health issues, industrial accidents and other business interruptions.\n",
      "     The Company has a large, global business with sales outside the U.S. representing a majority of the Company’s total net sales, and the Company believes that it generally benefits from growth in intern...\n",
      "\n",
      "#3    0.5532  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Business Risks > Future operating results depend upon the Company’s ability to obtain components in sufficient quantities on commercially reasonable terms.\n",
      "     Additionally, the Company’s new products often utilize custom components available from only one source. When a component or product uses new technologies, initial capacity constraints may exist until...\n",
      "\n",
      "#4    0.5520  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Business Risks > The Company is exposed to the risk of write-downs on the value of its inventory and other assets, in addition to purchase commitment cancellation risk.\n",
      "     The Company orders components for its products and builds inventory in advance of product announcements and shipments. Manufacturing purchase obligations cover the Company’s forecasted component and m...\n",
      "\n",
      "#5    0.5367  [text] TABLE OF CONTENTS > Wearables, Home and Accessories > Item 1A.    Risk Factors > Business Risks > The Company depends on component and product manufacturing and logistical services provided by outsourcing partners, many of which are located outside of the U.S.\n",
      "     Changes or additions to the Company’s supply chain require considerable time and resources and involve significant risks and uncertainties, including exposure to additional regulatory and operational ...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 7 — Demo Queries\n",
    "# =============================================================================\n",
    "\n",
    "# Example queries — adjust to match the filing content\n",
    "_ = semantic_search(\"What are the main risk factors?\")\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "_ = semantic_search(\"Revenue and net income figures\")\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "_ = semantic_search(\"Supply chain and manufacturing operations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_SEC_SemanticSearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
